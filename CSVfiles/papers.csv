abstract,citationCount,firstAuthor,influentialCitationCount,keywords,otherAuthors,pages,paperId,reviewers,title,venue,venueId,venueType,volume,year
"Graph Database Management Systems (GDBMSs) store data as graphs and allow the efficient querying of nodes and their relationships. Logic bugs are bugs that cause a GDBMS to return an incorrect result for a given query (e.g., by returning incorrect nodes or relationships). The impact of such bugs can be severe, as they often go unnoticed. The core insight of this paper is that Query Partitioning, a test oracle that has been proposed to test Relational Database Systems, is applicable to testing GDBMSs as well. The core idea of Query Partitioning is that, given a query, multiple queries are derived whose results can be combined to reconstruct the given query’s result. Any discrepancy in the result indicates a logic bug. We have implemented this approach as a practical tool named GDBMeter and evaluated GDBMeter on three popular GDBMSs and found a total of 40 unique, previously unknown bugs. We consider 14 of them to be logic bugs, the others being error or crash bugs. Overall, 27 of the bugs have been fixed, and 35 confirmed. We compared our approach to the state-of-the-art approach to testing GDBMS, which relies on differential testing; we found that it results in a high number of false alarms, while Query Partitioning reported actual logic bugs without any false alarms. Furthermore, despite the previous efforts in testing Neo4j and JanusGraph, we found 18 additional bugs. The developers appreciate our work and plan to integrate GDBMeter into their testing process. We expect that this simple, yet effective approach and the practical tool will be used to test other GDBMSs.",24,1663632797,2,"Management Systems, Database Management, Query Partitioning, Graph Database, Database Systems","2280834096, 1625425838, 38319925",,a2a514ed839dafdd0fb76d6c2615f25f35bf8087,"2108844303, 31131132, 2112662828, 1492120545",Testing Graph Database Engines via Query Partitioning,International Symposium on Software Testing and Analysis,289bfdda-eab3-4c9a-97be-ef1e0f9ddfc0,conference,,2023
"Graph database engines stand out in the era of big data for their efficiency of modeling and processing linked data. To assure high quality of graph database engines, it is highly critical to conduct automatic test generation for graph database engines, e.g., random test generation, the most commonly adopted approach in practice. However, random test generation faces the challenge of generating complex inputs (i.e., property graphs and queries) for producing non-empty query results; generating such type of inputs is important especially for detecting wrong-result bugs. To address this challenge, in this paper, we propose GDsmith, the first approach for testing Cypher graph database engines. GDsmith ensures that each randomly generated query satisfies the semantic requirements. To increase the probability of producing complex queries that return non-empty results, GDsmith includes two new techniques: graph-guided generation of complex pattern combinations and data-guided generation of complex conditions. Our evaluation results demonstrate that GDsmith is effective and efficient for producing complex queries that return non-empty results for bug detection, and substantially outperforms the baselines. GDsmith successfully detects 28 bugs on the released versions of three highly popular open-source graph database engines and receives positive feedback from their developers.",17,2171106811,3,"database engines, Graph database, big data, linked data, database","49661434, 31131132, 2118207557, 144281339, 5779643, 2057038192",,6c755fc901d0b41a5d73c265f64a5aacf62e83b8,"101108644, 1706922, 134898163, 143911374, 2093481779",GDsmith: Detecting Bugs in Cypher Graph Database Engines,International Symposium on Software Testing and Analysis,289bfdda-eab3-4c9a-97be-ef1e0f9ddfc0,conference,,2023
"ABSTRACT In this systems paper, we present MillenniumDB: a novel graph database engine that is modular, persistent, and open source. MillenniumDB is based on a graph data model, which we call domain graphs, that provides a simple abstraction upon which a variety of popular graph models can be supported, thus providing a flexible data management engine for diverse types of knowledge graph. The engine itself is founded on a combination of tried and tested techniques from relational data management, state-of-the-art algorithms for worst-case-optimal joins, as well as graph-specific algorithms for evaluating path queries. In this paper, we present the main design principles underlying MillenniumDB, describing the abstract graph model and query semantics supported, the concrete data model and query syntax implemented, as well as the storage, indexing, query planning and query evaluation techniques used. We evaluate MillenniumDB over real-world data and queries from the Wikidata knowledge graph, where we find that it outperforms other popular persistent graph database engines (including both enterprise and open source alternatives) that support similar query features.",14,2434366,3,"graph, systems paper, data, query, graph database","2059572334, 2772109, 144658846, 1754091, 1403082590, 144007515, 143678972, 1706922, 143911374",560-610,61c931d50f3e32f70abf1bccddf2479212dd2fde,"2424392, 2109512262, 1490915504, 70209653, 2131285720",MillenniumDB: An Open-Source Graph Database System,Data Intelligence,f80a2e54-1332-48bf-9634-4b2f77fca809,journal,5,2023
"
 Modern graph database query languages such as GQL, SQL/PGQ, and their academic predecessor G-Core promote paths to first-class citizens in the sense that their pattern matching facility can return
 paths
 , as opposed to only nodes and edges. This is challenging for database engines, since graphs can have a large number of paths between a given node pair, which can cause huge intermediate results in query evaluation.
 
 
 We introduce the concept of
 path multiset representations (PMRs)
 , which can represent multisets of paths exponentially succinctly and therefore bring significant advantages for representing intermediate results. We give a detailed theoretical analysis that shows that they are especially well-suited for representing results of regular path queries and extensions thereof involving counting, random sampling, and unions. Our experiments show that they drastically improve scalability for regular path query evaluation, with speedups of several orders of magnitude.
",17,144352362,1,"academic predecessor, predecessor G-Core, G-Core promote, first-class citizens, pattern matching","2879007, 2164445100, 2304958793, 1709642, 2434366",1790-1803,2c3eef2f17369912e330281d54b535675077e4ca,"1403082590, 143911374, 2054838160",Representing Paths in Graph Database Pattern Matching,Proceedings of the VLDB Endowment,fcbcaf18-8ab1-43e1-a973-604bbc7e344e,journal,16,2023
"Graph database systems (GDBs) allow efficiently storing and retrieving graph data, and have become the critical component in many applications, e.g., knowledge graphs, social networks, and fraud detection. It is important to ensure that GDBs operate correctly. Logic bugs can occur and make GDBs return an incorrect result for a given query. These bugs are critical and can easily go unnoticed by developers when the graph and queries become complicated. Despite the importance of GDBs, logic bugs in GDBs have received less attention than those in relational database systems. In this paper, we present Grand, an approach for automatically finding logic bugs in GDBs that adopt Gremlin as their query language. The core idea of Grand is to construct semantically equivalent databases for multiple GDBs, and then compare the results of a Gremlin query on these databases. If the return results of a query on multiple GDBs are different, the likely cause is a logic bug in these GDBs. To effectively test GDBs, we propose a model-based query generation approach to generate valid Gremlin queries that can potentially return non-empty results, and a data mapping approach to unify the format of query results for different GDBs. We evaluate Grand on six widely-used GDBs, e.g., Neo4j and HugeGraph. In total, we have found 21 previously-unknown logic bugs in these GDBs. Among them, developers have confirmed 18 bugs, and fixed 7 bugs.",31,2158585032,3,"GDBs, Logic bugs, bugs, social networks, fraud detection","2964640, 134898163, 2093481779, 2131285720, 2118120527, 2152692124, 40231586, 144525882",,e67a2817089312746d69b38ce9abfdc4b1bc69c3,"2109512262, 2054838160, 144615268, 66327914",Finding bugs in Gremlin-based graph database systems via Randomized differential testing,International Symposium on Software Testing and Analysis,289bfdda-eab3-4c9a-97be-ef1e0f9ddfc0,conference,,2022
,17,144615268,0,,2140474907,515-537,fe4c5074f021cd1c810892c1b6bc267b23aa6e5c,"2112409349, 2695617, 2142659443, 2118207557",Fraud detection in the distributed graph database,Cluster Computing,f1d0ef3d-4e90-41e9-b454-f589a933654f,journal,26,2022
"Most products at ByteDance, e.g., TikTok, Douyin, and Toutiao, naturally generate massive amounts of graph data. To efficiently store, query and update massive graph data is challenging for the broad range of products at ByteDance with various performance requirements. We categorize graph workloads at ByteDance into three types: online analytical, transaction, and serving processing, where each workload has its own characteristics. Existing graph databases have different performance bottlenecks in handling these workloads and none can efficiently handle the scale of graphs at ByteDance. We developed ByteGraph to process these graph workloads with high throughput, low latency and high scalability. There are several key designs in ByteGraph that make it efficient for processing our workloads, including edge-trees to store adjacency lists for high parallelism and low memory usage, adaptive optimizations on thread pools and indexes, and geographic replications to achieve fault tolerance and availability. ByteGraph has been in production use for several years and its performance has shown to be robust for processing a wide range of graph workloads at ByteDance.",20,2145413970,2,"naturally generate, graph data, Douyin, graph, graph workloads","2108844303, 2167037428, 1490915504, 2145763285, 2109512262, 123816348, 2088215217, 2344391699, 32058742, 2116124684, 2144671306, 2424392, 2182246691, 2112662828, 2184079980, 113398129, 2695617, 2321412875, 2112409349, 46255707, 2157513188, 2153604994, 2113918898, 50841357, 2116502347",3306-3318,d1ae4ab5047489c2b010c7ce72262982ad66ad60,"2158585032, 2115256817, 2142659443, 7790877, 2152692124",ByteGraph: A High-Performance Distributed Graph Database in ByteDance,Proceedings of the VLDB Endowment,fcbcaf18-8ab1-43e1-a973-604bbc7e344e,journal,15,2022
,12,2108844303,0,,"2145413970, 72117196, 2150609388, 2115219530, 2116502347, 2151811827",2545-2558,75a8faa6861b7fdd49b36615df1835f1c4bbcb65,"2321412875, 23214019, 49661434",G-Tran: A High Performance Distributed Graph Database with a Decentralized Architecture,Proceedings of the VLDB Endowment,fcbcaf18-8ab1-43e1-a973-604bbc7e344e,journal,15,2022
"A graph database is a type of NoSQL database that uses graph structure for semantic queries with nodes, edges, and properties to represent and store data. It has been applied in many fields, such as education, health, business, and social network, with many famous applications such as Google, Facebook, and eBay. One of the main advantages of the graph database is its effective performance in data queries. This paper presents a comprehensive comparison of the performance based on the execution time of a NoSQL graph database named Neo4J with a popular relational database system, MySQL, which is used as the underlying technology in developing a software system. Query types are categorized into four groups: selection/ search, recursion, aggregation, and pattern matching. We examined representative questions for each group and executed them on Neo4j and MySQL using a real-life dataset named Career Village. The results show that Neo4j’s data query performance is better than MySQL in most results.",8,10313020,0,"graph database, database, semantic queries, graph structure, graph","2192611227, 23214019, 2065718",,5534c3b8bfe03ec0ee3ea3aafd0a4471b07f8b7d,"2116502347, 2145413970, 2118120527, 2108844303, 150358651",Query-based Performance Comparison of Graph Database and Relational Database,Symposium on Information and Communication Technology,8f515bf7-e3c7-4242-85e5-14de4c29e76c,conference,,2022
"Background The COVID-19 epidemic is still spreading globally. Contact tracing is a vital strategy in epidemic emergency management; however, traditional contact tracing faces many limitations in practice. The application of digital technology provides an opportunity for local governments to trace the contacts of individuals with COVID-19 more comprehensively, efficiently, and precisely. Objective Our research aimed to provide new solutions to overcome the limitations of traditional contact tracing by introducing the organizational process, technical process, and main achievements of digital contact tracing in Hainan Province. Methods A graph database algorithm, which can efficiently process complex relational networks, was applied in Hainan Province; this algorithm relies on a governmental big data platform to analyze multisource COVID-19 epidemic data and build networks of relationships among high-risk infected individuals, the general population, vehicles, and public places to identify and trace contacts. We summarized the organizational and technical process of digital contact tracing in Hainan Province based on interviews and data analyses. Results An integrated emergency management command system and a multi-agency coordination mechanism were formed during the emergency management of the COVID-19 epidemic in Hainan Province. The collection, storage, analysis, and application of multisource epidemic data were realized based on the government’s big data platform using a centralized model. The graph database algorithm is compatible with this platform and can analyze multisource and heterogeneous big data related to the epidemic. These practices were used to quickly and accurately identify and trace 10,871 contacts among hundreds of thousands of epidemic data records; 378 closest contacts and a number of public places with high risk of infection were identified. A confirmed patient was found after quarantine measures were implemented by all contacts. Conclusions During the emergency management of the COVID-19 epidemic, Hainan Province used a graph database algorithm to trace contacts in a centralized model, which can identify infected individuals and high-risk public places more quickly and accurately. This practice can provide support to government agencies to implement precise, agile, and evidence-based emergency management measures and improve the responsiveness of the public health emergency response system. Strengthening data security, improving tracing accuracy, enabling intelligent data collection, and improving data-sharing mechanisms and technologies are directions for optimizing digital contact tracing.",20,2054289955,1,"Hainan Province, Contact tracing, Hainan, Province, data","101108644, 2054838160, 1492120545, 2115905112",N/A,1cff064f815111a71a98afda7aee1867ad617901,"2051972259, 123816348, 2065718, 49661434",Digital Contact Tracing Based on a Graph Database Algorithm for Emergency Management During the COVID-19 Epidemic: Case Study,JMIR mHealth and uHealth,bb899a20-6789-46e4-9ed0-c7c284028fd9,journal,9,2021
,23,70209653,1,,"2070468032, 7790877",1 - 20,7bb477077968d68aa7a6059d8d6d801fb28274da,"3010622, 2304958793, 134898163",Credit Card Fraud Detection Technique by Applying Graph Database Model,The Arabian journal for science and engineering,9bc76c9a-64ac-4dd9-902e-80fccca1833f,journal,46,2021
"Ontologies, and especially formal ones, have traditionally been investigated as a means to formalize an application domain so as to carry out automated reasoning on it. The union of the terminological part of an ontology and the corresponding assertional part is known as a Knowledge Graph. On the other hand, database technology has often focused on the optimal organization of data so as to boost efficiency in their storage, management and retrieval. Graph databases are a recent technology specifically focusing on element-driven data browsing rather than on batch processing. While the complementarity and connections between these technologies are patent and intuitive, little exists to bring them to full integration and cooperation. This paper aims at bridging this gap, by proposing an intermediate format that can be easily mapped onto the formal ontology on one hand, so as to allow complex reasoning, and onto the graph database on the other, so as to benefit from efficient data handling.",23,1725650,0,"application domain, Knowledge Graph, automated reasoning, Graph, Ontologies",,N/A,21042565ec941f4fa31ac5a0af85a1a84ff21f1b,"113398129, 23214019, 1492120545, 7790877, 2093481779",Integration Strategy and Tool between Formal Ontology and Graph Database Technology,Electronics,ccd8e532-73c6-414f-bc91-271bbb2933e2,journal,N/A,2021
"Effective data interoperability and schedule analysis play a significant role in improving the management of prefabricated buildings. However, there is a lack of efficient strategies and comprehensive approaches for data interoperability and data-based automated schedule analysis. This paper intends to promote prefabricated buildings’ management by solving these two problems via developing an IFC-based framework consisting of three parts. Firstly, this framework proposed a mechanism to establish an IFC-based 4D construction management information model of prefabricated buildings. Furthermore, a non-relational database—graph database—is introduced to twin this model into a task-centered network to realize the interoperation of construction information among different participants. Finally, graph database-based strategies to update data, automatically analyze construction schedules and visualize the 4D construction management information model are described. The proposed framework is validated in a prefabricated engineering case. In this case, an IFC-based and graph database-based 4D construction management information model is established through IFC standard’s extension. The graph database-based analysis of the model automatically recognizes the engineering case’s critical path information, delay analysis information, and schedule network analysis information. It is illustrated that this framework can successfully establish a unified IFC-based information model of prefabricated buildings’ construction management to prompt effective data interoperability. In addition, the application of this IFC-based information model in graph database can automatically analyze the construction schedules to prevent possible delays in advance. In short, the significance of this paper is to innovatively propose an IFC-based and graph data-based information model to solve the difficulties of ineffective data interoperation and unautomated schedule analysis in prefabricated buildings’ construction management. This study can be the digital foundation of further IFC-based digital twin.",13,98831679,0,"information, information model, construction management, construction, model","2153317609, 2142659443, 30188257, 2108248686, 2117925465",N/A,9b3e8d202488dc29e601fc471a25a2af9002659e,"2171106811, 2116124684, 144281339",IFC-Based 4D Construction Management Information Model of Prefabricated Buildings and Its Application in Graph Database,Applied Sciences,136edf8d-0f88-4c2c-830f-461c6a9b842e,journal,N/A,2021
"As data grow both in size and in connectivity, the interest to use graph databases in the industry has been proliferating. However, there has been little research on graph database education. In response to the need to introduce college students to graph databases, this paper is the first to analyze students' errors in homework submissions of queries written in Cypher, the query language for Neo4j---the most prominent graph database. Based on 40,093 student submissions from homework assignments in an upper-level computer science database course at one university, this paper provides a quantitative analysis of students' learning when solving graph database problems. The data shows that students struggle the most to correctly use Cypher's WITH clause to define variable names before referencing in the WHERE clause and these errors persist over multiple homework problems requiring the same techniques, and we suggest a further improvement on the classification of syntactic errors.",8,153314895,0,"graph database, graph, database, data grow, database education","66327914, 2051972259, 2517099",,09f54c64b39f5f7e7570f9f4ce3e3af544401e14,"144525882, 150358651, 2184079980, 2164445100, 101108644",A Quantitative Analysis of Student Solutions to Graph Database Problems,Annual Conference on Innovation and Technology in Computer Science Education,e82485bc-2195-4cf5-9f9a-012501918b2f,conference,,2021
,15,2115256817,1,,"150358651, 19262604, 2873542",,a604aa1f2a2ca1a6a0b09013e71b83d36cc0f358,"144525882, 2424392, 2344391699, 2140474907",An Empirical Study on Recent Graph Database Systems,"Knowledge Science, Engineering and Management",3e22d1e0-9b11-40a4-ac7c-0ebe5825316e,conference,,2020
"Although graph databases have extensively found applications in the relationship-centered era, a time-version support is seldom provided. While current storage systems capture the most recently updated snapshot of the underlying graph, most real world graphs embed a dynamic behavior translating the fact that vertices or edges can join or leave the graph at any time instant. Regarding that, a graph database should faithfully maintain the state of every graph's element permitting the analysis and prediction of the underlying system's performance. Since physical deletions are forbidden in such a scenario, the outgrowing size of data is a crippling restriction steering the interest in this area towards the optimization of the persistent storage. However, capturing and storing the state of the graph as full snapshots adds a storage overhead traded by faster query responses. Accordingly, the choice of an appropriate storage engine should be adapted with the threshold of accepted query latencies and the available storage resources. This paper will recognize the anterior academic work in the era of temporal graph databases while highlighting the existing tradeoff between storage and computation time costs. The implementation of GDBAlive, a temporal graph database using two state-of-the-art techniques Copy+Log and Log, is provided relying on a robust column oriented data store. In order to optimize the responsiveness of temporal queries in terms of computation times, we will introduce two fetching strategies ""AsyncFS"" and ""Forced Fetch"" and prove their efficiency on a real dataset.",13,2148303656,0,"extensively found, found applications, time-version support, graph, graph databases","66913593, 3010622",N/A,0601e9e434b30320c316c76228b97c093fa98ad6,"2280834096, 70209653, 2152692124, 2517099",GDBAlive: A Temporal Graph Database Built on Top of a Columnar Data Store,Journal of Advances in Information Technology,f4784c7b-6592-49eb-a116-7290e0398868,journal,N/A,2020
,153,2772109,11,,,,91d6e8ba5dd90b02fe3bd870b19da13a6167af53,"40231586, 1492120545, 2321412875, 2051972259, 2113918898",The Property Graph Database Model,Alberto Mendelzon Workshop on Foundations of Data Management,66257d67-2035-4ff6-b62a-4099db02fcde,conference,,2018
